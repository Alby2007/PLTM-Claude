"""
Semantic Conflict Detector V2 - Complete Implementation

3-stage conflict detection:
1. Explicit conflicts (fast, rule-based)
2. World knowledge conflicts (fast, lookup)  
3. Semantic conflicts (slow, LLM with caching)

Expected improvement: 74% â†’ 88% on 300-test benchmark
"""

from typing import Optional, Tuple
import json
import os
from loguru import logger

from src.core.models import MemoryAtom


class SemanticConflictDetectorV2:
    """
    Comprehensive semantic conflict detector with LLM fallback
    """
    
    def __init__(self, llm_model: str = "claude-sonnet-4-20250514"):
        self.llm_model = llm_model
        self.llm_enabled = os.getenv("ANTHROPIC_API_KEY") is not None
        
        # World knowledge base
        self.world_knowledge = self._load_world_knowledge()
        
        # Cache semantic decisions
        self.cache = {}
        
        # Stats
        self.stats = {
            "explicit": 0,
            "world_knowledge": 0,
            "llm_semantic": 0,
            "no_conflict": 0,
            "cache_hits": 0
        }
        
        logger.info(f"SemanticConflictDetectorV2 initialized (LLM: {self.llm_enabled})")
    
    def _load_world_knowledge(self) -> dict:
        """Load comprehensive world knowledge base"""
        return {
            "dietary_restrictions": {
                "vegan": {"excludes": ["meat", "dairy", "eggs", "fish", "steak", "chicken", "cheese", "milk", "beef", "pork"]},
                "vegetarian": {"excludes": ["meat", "fish", "steak", "chicken", "pork", "beef"]},
                "lactose_intolerant": {"excludes": ["dairy", "milk", "cheese", "yogurt", "cream"]},
                "allergic_to_dairy": {"excludes": ["dairy", "milk", "cheese", "yogurt", "butter", "cream"]},
                "gluten_free": {"excludes": ["bread", "pasta", "wheat", "gluten"]},
            },
            
            "lifestyle_patterns": {
                "morning_person": {
                    "conflicts": ["works_late_night", "productive_night", "night_owl", "best_work_at_night", "late_night"]
                },
                "night_owl": {
                    "conflicts": ["wakes_early", "morning_person", "productive_morning", "early_riser"]
                },
                "sedentary": {
                    "conflicts": ["works_out_daily", "athlete", "very_active", "runs_marathons", "marathon"]
                },
                "health_conscious": {
                    "conflicts": ["eats_fast_food_daily", "unhealthy_diet", "fast_food_every"]
                },
                "minimalist": {
                    "conflicts": ["hoards", "collects_everything", "never_throw"]
                },
            },
            
            "professional_requirements": {
                "data_scientist": {"requires": ["python", "statistics", "programming", "data"]},
                "frontend_developer": {"requires": ["javascript", "html", "css", "js"]},
                "backend_developer": {"requires": ["programming", "databases", "server"]},
                "doctor": {"requires": ["medical_training", "medical_knowledge", "medical"]},
                "lawyer": {"requires": ["law_degree", "bar_exam", "legal"]},
                "pilot": {"requires": ["flying", "aviation", "fly", "plane"]},
                "chef": {"requires": ["cooking", "cook"]},
                "musician": {"requires": ["instrument", "music", "play"]},
                "writer": {"requires": ["writing", "write"]},
                "database_administrator": {"requires": ["sql", "databases", "database"]},
                "dba": {"requires": ["sql", "databases"]},
                "machine_learning_engineer": {"requires": ["linear_algebra", "math", "ml"]},
                "devops_engineer": {"requires": ["command_line", "terminal", "cli"]},
                "security_expert": {"requires": ["security", "encryption", "crypto"]},
            },
            
            "behavioral_contradictions": {
                "always_double_checks": {"conflicts": ["frequently_pushes_broken", "careless", "broken_code"]},
                "extremely_competitive": {"conflicts": ["doesn't_care_about_winning", "indifferent"]},
                "introvert": {"conflicts": ["loves_large_parties", "loves_parties", "social_butterfly"]},
                "extrovert": {"conflicts": ["hermit", "avoids_people", "never_leaves_home"]},
                "patient": {"conflicts": ["frustrated_immediately", "gets_frustrated"]},
                "organized": {"conflicts": ["cant_find_anything", "never_find", "messy"]},
                "frugal": {"conflicts": ["buys_luxury", "expensive_purchases", "bought_ferrari"]},
                "generous": {"conflicts": ["never_helps", "selfish"]},
                "honest": {"conflicts": ["lies_constantly", "lie"]},
                "collaborative": {"conflicts": ["refuses_to_work_with_others", "refuse_work"]},
            },
        }
    
    async def detect_conflict(
        self,
        atom1: MemoryAtom,
        atom2: MemoryAtom
    ) -> Tuple[bool, Optional[str]]:
        """
        3-stage conflict detection pipeline
        
        Returns:
            (has_conflict, reasoning)
        """
        # Stage 1: Explicit conflicts (fast, rule-based)
        explicit = self._check_explicit_conflict(atom1, atom2)
        if explicit:
            self.stats["explicit"] += 1
            return True, "Explicit opposite predicates"
        
        # Stage 2: World knowledge (fast, lookup)
        wk_conflict = self._check_world_knowledge_conflict(atom1, atom2)
        if wk_conflict:
            self.stats["world_knowledge"] += 1
            return True, wk_conflict
        
        # Stage 3: Semantic (slow, LLM with caching)
        if self.llm_enabled:
            semantic = await self._check_semantic_conflict(atom1, atom2)
            if semantic:
                self.stats["llm_semantic"] += 1
                return True, semantic
        
        self.stats["no_conflict"] += 1
        return False, None
    
    def _check_explicit_conflict(self, atom1: MemoryAtom, atom2: MemoryAtom) -> bool:
        """Check explicit opposite predicates"""
        opposite_pairs = [
            ("likes", "dislikes"),
            ("loves", "hates"),
            ("prefers", "avoids"),
            ("trusts", "distrusts"),
            ("supports", "opposes"),
            ("agrees", "disagrees"),
            ("believes_in", "doubts"),
        ]
        
        for pred1, pred2 in opposite_pairs:
            if (atom1.predicate == pred1 and atom2.predicate == pred2) or \
               (atom1.predicate == pred2 and atom2.predicate == pred1):
                if self._similar_objects(atom1.object, atom2.object):
                    return True
        
        # Exclusive predicates
        exclusive = ["works_at", "lives_in", "is", "studies_at", "member_of"]
        if atom1.predicate in exclusive and atom2.predicate in exclusive:
            if atom1.predicate == atom2.predicate:
                if not self._similar_objects(atom1.object, atom2.object):
                    return True
        
        return False
    
    def _check_world_knowledge_conflict(
        self,
        atom1: MemoryAtom,
        atom2: MemoryAtom
    ) -> Optional[str]:
        """Check world knowledge base for conflicts"""
        
        # Dietary restrictions
        for diet, rules in self.world_knowledge["dietary_restrictions"].items():
            if diet in atom1.object.lower() or diet.replace("_", " ") in atom1.object.lower():
                for excluded in rules["excludes"]:
                    if excluded in atom2.object.lower():
                        return f"{diet} excludes {excluded}"
            
            if diet in atom2.object.lower() or diet.replace("_", " ") in atom2.object.lower():
                for excluded in rules["excludes"]:
                    if excluded in atom1.object.lower():
                        return f"{diet} excludes {excluded}"
        
        # Lifestyle patterns
        for lifestyle, rules in self.world_knowledge["lifestyle_patterns"].items():
            lifestyle_normalized = lifestyle.replace("_", " ")
            
            if lifestyle in atom1.object.lower() or lifestyle_normalized in atom1.object.lower():
                for conflict in rules.get("conflicts", []):
                    conflict_normalized = conflict.replace("_", " ")
                    if conflict in atom2.object.lower() or conflict_normalized in atom2.object.lower():
                        return f"{lifestyle} conflicts with {conflict}"
            
            if lifestyle in atom2.object.lower() or lifestyle_normalized in atom2.object.lower():
                for conflict in rules.get("conflicts", []):
                    conflict_normalized = conflict.replace("_", " ")
                    if conflict in atom1.object.lower() or conflict_normalized in atom1.object.lower():
                        return f"{lifestyle} conflicts with {conflict}"
        
        # Professional requirements
        for profession, rules in self.world_knowledge["professional_requirements"].items():
            profession_normalized = profession.replace("_", " ")
            
            # Check if atom1 claims profession
            if profession in atom1.object.lower() or profession_normalized in atom1.object.lower():
                # Check if atom2 denies a requirement
                for requirement in rules["requires"]:
                    if requirement in atom2.object.lower():
                        # Check for denial predicates
                        if atom2.predicate in ["never_uses", "doesn't_know", "doesn't_have", "never", "dont_know"]:
                            return f"{profession} requires {requirement}"
                        # Check for denial in object
                        if any(denial in atom2.object.lower() for denial in ["never", "don't", "doesn't", "cant", "cannot"]):
                            return f"{profession} requires {requirement}"
        
        # Behavioral contradictions
        for behavior, rules in self.world_knowledge["behavioral_contradictions"].items():
            behavior_normalized = behavior.replace("_", " ")
            
            if behavior in atom1.object.lower() or behavior_normalized in atom1.object.lower():
                for conflict in rules.get("conflicts", []):
                    conflict_normalized = conflict.replace("_", " ")
                    if conflict in atom2.object.lower() or conflict_normalized in atom2.object.lower():
                        return f"{behavior} conflicts with {conflict}"
            
            if behavior in atom2.object.lower() or behavior_normalized in atom2.object.lower():
                for conflict in rules.get("conflicts", []):
                    conflict_normalized = conflict.replace("_", " ")
                    if conflict in atom1.object.lower() or conflict_normalized in atom1.object.lower():
                        return f"{behavior} conflicts with {conflict}"
        
        return None
    
    async def _check_semantic_conflict(
        self,
        atom1: MemoryAtom,
        atom2: MemoryAtom
    ) -> Optional[str]:
        """Use LLM to detect semantic conflicts (with caching)"""
        
        # Check cache first
        cache_key = self._make_cache_key(atom1, atom2)
        if cache_key in self.cache:
            self.stats["cache_hits"] += 1
            return self.cache[cache_key]
        
        # Ask LLM
        prompt = f"""You are an expert at detecting contradictions in statements about a person.

Determine if these two facts about a user conflict with each other:

Fact 1: User {atom1.predicate} {atom1.object}
Fact 2: User {atom2.predicate} {atom2.object}

Consider:
1. Explicit contradictions (e.g., "likes X" vs "hates X")
2. Implicit contradictions (e.g., "morning person" vs "works best at night")
3. Behavioral inconsistencies (e.g., "always careful" vs "frequently careless")
4. Logical impossibilities (e.g., "in London at 2pm" vs "in Tokyo at 3pm same day")

Do these facts conflict?

Respond in JSON format:
{{
    "conflict": true/false,
    "reasoning": "brief explanation",
    "confidence": 0.0-1.0
}}

Be conservative - only mark as conflict if there's a clear contradiction."""
        
        try:
            response = await self._call_llm(prompt)
            result = json.loads(response)
            
            if result["conflict"] and result["confidence"] > 0.7:
                reasoning = result["reasoning"]
                self.cache[cache_key] = reasoning
                return reasoning
            else:
                self.cache[cache_key] = None
                return None
        
        except Exception as e:
            logger.warning(f"LLM semantic check failed: {e}")
            self.cache[cache_key] = None
            return None
    
    def _similar_objects(self, obj1: str, obj2: str) -> bool:
        """Check if two objects are semantically similar"""
        obj1_clean = obj1.lower().strip()
        obj2_clean = obj2.lower().strip()
        
        if obj1_clean == obj2_clean:
            return True
        
        if obj1_clean in obj2_clean or obj2_clean in obj1_clean:
            return True
        
        return False
    
    def _make_cache_key(self, atom1: MemoryAtom, atom2: MemoryAtom) -> str:
        """Create cache key for semantic conflict check"""
        return f"{atom1.predicate}:{atom1.object}|{atom2.predicate}:{atom2.object}"
    
    async def _call_llm(self, prompt: str) -> str:
        """Call Claude for semantic reasoning"""
        import anthropic
        
        client = anthropic.Anthropic()
        
        message = client.messages.create(
            model=self.llm_model,
            max_tokens=500,
            temperature=0.0,
            messages=[{"role": "user", "content": prompt}]
        )
        
        return message.content[0].text
    
    def get_stats(self) -> dict:
        """Get detection statistics"""
        total = sum(self.stats.values()) - self.stats["cache_hits"]
        
        if total == 0:
            return self.stats
        
        return {
            **self.stats,
            "cache_hit_rate": f"{self.stats['cache_hits'] / (self.stats['llm_semantic'] + self.stats['cache_hits']) * 100:.1f}%" if self.stats['llm_semantic'] + self.stats['cache_hits'] > 0 else "0%"
        }
